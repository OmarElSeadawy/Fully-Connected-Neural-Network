{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy.misc import *\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pickle import *\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo)\n",
    "        return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Reading all the Data\n",
    "datadict = unpickle(\"./Data/cifar-100-python/train\")\n",
    "xTrain = datadict[b'data']\n",
    "yTrain = datadict[b'coarse_labels']\n",
    "xtr= xTrain[:40000]\n",
    "ytr= yTrain[:40000]\n",
    "xval = xTrain[40000:]\n",
    "yval = yTrain[40000:]\n",
    "\n",
    "xtrt = xtr.reshape(40000,3,32,32)\n",
    "\n",
    "datadicttest = unpickle(\"./Data/cifar-100-python/test\")\n",
    "xtest = datadicttest[b'data']\n",
    "ytest = datadicttest[b'coarse_labels']\n",
    "valid_examples = xtest.shape[0]\n",
    "\n",
    "#Data Preprocessing (Zero Centering and Normalization)\n",
    "xtr = np.array(xtr,dtype=np.float64)\n",
    "xtr -= np.mean(xtr)\n",
    "xtr /= 255\n",
    "xval = np.array(xval,dtype=np.float64)\n",
    "xval -= np.mean(xval)\n",
    "xval /= 255\n",
    "xtest = np.array(xtest,dtype=np.float64)\n",
    "xtest -= np.mean(xtest)\n",
    "xtest /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Softmax Function to Calculate Losses\n",
    "def SoftmaxFn(classscores,y):                 \n",
    "    exps = np.exp(classscores,dtype=np.float64)\n",
    "    probability = exps / np.sum(exps, axis=1, keepdims=True)\n",
    "    q = exps.shape[0]\n",
    "    correct_log = -np.log(probability[np.arange(q),y] + 1e-9)             \n",
    "    return correct_log,probability\n",
    "\n",
    "#Leaky ReLU Implementation\n",
    "def ReLUFwd(x):                               \n",
    "    return np.maximum(0.1*x,x,dtype=np.float64)\n",
    "\n",
    "#Forward Pass (MultAdd and ReLU)\n",
    "def FwdPass(w,b,layers,E,x,MiniBatchSize):\n",
    "    layers_step = []\n",
    "    current = x[E*MiniBatchSize:(E+1)*MiniBatchSize]\n",
    "    for q in range(len(layers)-1):\n",
    "        HiddenLayer = ReLUFwd(np.dot(current,w[q])+b[q])\n",
    "        layers_step.append(HiddenLayer)\n",
    "        current = HiddenLayer\n",
    "    return current,layers_step\n",
    "\n",
    "#Back Propagation using Analytic Gradient Method\n",
    "def BackwdPass(E,layers,layers_step,probability,ytr,Examples,w,MiniBatchSize):\n",
    "    gradient_scores = probability\n",
    "    gradient_scores[np.arange(MiniBatchSize),ytr[E*MiniBatchSize:(E+1)*MiniBatchSize]] -= 1\n",
    "    gradient_scores /= MiniBatchSize\n",
    "    derivative_step = gradient_scores\n",
    "    dw = []\n",
    "    db = []\n",
    "    for i in reversed(range(len(layers_step)-1)):\n",
    "        dw.append(np.dot(layers_step[i].T,derivative_step))\n",
    "        db.append(np.sum(derivative_step,axis=0,keepdims=True))\n",
    "        dh = np.dot(derivative_step,w[i+1].T)\n",
    "        dh[layers_step[i] <= 0] *= 0.1\n",
    "        derivative_step = dh\n",
    "    dw.append(np.dot(xtr[E*MiniBatchSize:(E+1)*MiniBatchSize].T,dh))\n",
    "    db.append(np.sum(dh,axis=0,keepdims=True))\n",
    "    return dw,db\n",
    "\n",
    "#Initializing Weights using Xavier/2\n",
    "def XavierInit(layers):\n",
    "    #random seed\n",
    "    np.random.seed(5)\n",
    "    for i in range(len(layers)-1):\n",
    "        w.append(np.random.randn(layers[i],layers[i+1])/np.sqrt(layers[i]/2)) \n",
    "        b.append(np.zeros((layers[i+1])))\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Epochs\n",
    "Epochs = 100\n",
    "\n",
    "#Mini Batch Size and Layer Details\n",
    "MiniBatchSize = 200\n",
    "layers = [3072,1250,750,300,20]\n",
    "\n",
    "#HyperParameters\n",
    "learn_rate = 5e-3\n",
    "reg = 1e-4         #lambda Regularization strength\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, ' / ', 100, ' Total_Loss: ', 4.206643826251567, ', Loss : ', 3.916948697628691)\n",
      "('Training Accuracy : ', 0.145)\n",
      "('Validation Loss : ', 2.7327525484163653)\n",
      "('Validation Accuracy : ', 0.1708)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 1, ' / ', 100, ' Total_Loss: ', 2.985025590813682, ', Loss : ', 2.6951580784717204)\n",
      "('Training Accuracy : ', 0.185)\n",
      "('Validation Loss : ', 2.670120516009579)\n",
      "('Validation Accuracy : ', 0.1882)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 2, ' / ', 100, ' Total_Loss: ', 2.9404623018713196, ', Loss : ', 2.650630125476672)\n",
      "('Training Accuracy : ', 0.19)\n",
      "('Validation Loss : ', 2.63656981976001)\n",
      "('Validation Accuracy : ', 0.1964)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 3, ' / ', 100, ' Total_Loss: ', 2.9123068518689808, ', Loss : ', 2.6225042918562043)\n",
      "('Training Accuracy : ', 0.19)\n",
      "('Validation Loss : ', 2.608570393191279)\n",
      "('Validation Accuracy : ', 0.2044)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 4, ' / ', 100, ' Total_Loss: ', 2.886955061236555, ', Loss : ', 2.5971798746760273)\n",
      "('Training Accuracy : ', 0.205)\n",
      "('Validation Loss : ', 2.5867624738536876)\n",
      "('Validation Accuracy : ', 0.2119)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 5, ' / ', 100, ' Total_Loss: ', 2.8657432589148595, ', Loss : ', 2.5759932990447045)\n",
      "('Training Accuracy : ', 0.22)\n",
      "('Validation Loss : ', 2.566543169803287)\n",
      "('Validation Accuracy : ', 0.2199)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 6, ' / ', 100, ' Total_Loss: ', 2.847033521303432, ', Loss : ', 2.557307909178889)\n",
      "('Training Accuracy : ', 0.22)\n",
      "('Validation Loss : ', 2.5494249766764363)\n",
      "('Validation Accuracy : ', 0.2282)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 7, ' / ', 100, ' Total_Loss: ', 2.8304570098409987, ', Loss : ', 2.540753681940836)\n",
      "('Training Accuracy : ', 0.23)\n",
      "('Validation Loss : ', 2.53406536130963)\n",
      "('Validation Accuracy : ', 0.2318)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 8, ' / ', 100, ' Total_Loss: ', 2.815601292149964, ', Loss : ', 2.525919117817086)\n",
      "('Training Accuracy : ', 0.24)\n",
      "('Validation Loss : ', 2.5221136893488367)\n",
      "('Validation Accuracy : ', 0.234)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 9, ' / ', 100, ' Total_Loss: ', 2.8023784410412156, ', Loss : ', 2.5127185930390663)\n",
      "('Training Accuracy : ', 0.225)\n",
      "('Validation Loss : ', 2.511948131371788)\n",
      "('Validation Accuracy : ', 0.2367)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 10, ' / ', 100, ' Total_Loss: ', 2.790843663013871, ', Loss : ', 2.5012049634069293)\n",
      "('Training Accuracy : ', 0.245)\n",
      "('Validation Loss : ', 2.5021668399230816)\n",
      "('Validation Accuracy : ', 0.2403)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 11, ' / ', 100, ' Total_Loss: ', 2.7799718055125866, ', Loss : ', 2.490354371446213)\n",
      "('Training Accuracy : ', 0.255)\n",
      "('Validation Loss : ', 2.4935474263246835)\n",
      "('Validation Accuracy : ', 0.2433)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 12, ' / ', 100, ' Total_Loss: ', 2.770153280945, ', Loss : ', 2.4805579727640565)\n",
      "('Training Accuracy : ', 0.25)\n",
      "('Validation Loss : ', 2.483775621416429)\n",
      "('Validation Accuracy : ', 0.2472)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 13, ' / ', 100, ' Total_Loss: ', 2.760811930664088, ', Loss : ', 2.4712407874097297)\n",
      "('Training Accuracy : ', 0.26)\n",
      "('Validation Loss : ', 2.4764100157417457)\n",
      "('Validation Accuracy : ', 0.2479)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 14, ' / ', 100, ' Total_Loss: ', 2.7516690878290855, ', Loss : ', 2.462123076636408)\n",
      "('Training Accuracy : ', 0.26)\n",
      "('Validation Loss : ', 2.4693851526104154)\n",
      "('Validation Accuracy : ', 0.2504)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 15, ' / ', 100, ' Total_Loss: ', 2.743057976898085, ', Loss : ', 2.453538274486708)\n",
      "('Training Accuracy : ', 0.255)\n",
      "('Validation Loss : ', 2.461738416781532)\n",
      "('Validation Accuracy : ', 0.2527)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 16, ' / ', 100, ' Total_Loss: ', 2.7355680692316158, ', Loss : ', 2.4460754046444206)\n",
      "('Training Accuracy : ', 0.255)\n",
      "('Validation Loss : ', 2.4549627481550704)\n",
      "('Validation Accuracy : ', 0.2546)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 17, ' / ', 100, ' Total_Loss: ', 2.727585550548595, ', Loss : ', 2.4381202896887566)\n",
      "('Training Accuracy : ', 0.25)\n",
      "('Validation Loss : ', 2.4476352700316837)\n",
      "('Validation Accuracy : ', 0.2562)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 18, ' / ', 100, ' Total_Loss: ', 2.7200318202049276, ', Loss : ', 2.4305949839792955)\n",
      "('Training Accuracy : ', 0.25)\n",
      "('Validation Loss : ', 2.4416876893835444)\n",
      "('Validation Accuracy : ', 0.2592)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 19, ' / ', 100, ' Total_Loss: ', 2.7129559083583583, ', Loss : ', 2.423546930257698)\n",
      "('Training Accuracy : ', 0.25)\n",
      "('Validation Loss : ', 2.435482476789537)\n",
      "('Validation Accuracy : ', 0.2613)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 20, ' / ', 100, ' Total_Loss: ', 2.7055949575346925, ', Loss : ', 2.416214368709483)\n",
      "('Training Accuracy : ', 0.245)\n",
      "('Validation Loss : ', 2.4289432670677367)\n",
      "('Validation Accuracy : ', 0.2641)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 21, ' / ', 100, ' Total_Loss: ', 2.6985325550021826, ', Loss : ', 2.4091806836965124)\n",
      "('Training Accuracy : ', 0.245)\n",
      "('Validation Loss : ', 2.4243168209188655)\n",
      "('Validation Accuracy : ', 0.2658)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 22, ' / ', 100, ' Total_Loss: ', 2.6917773843691033, ', Loss : ', 2.4024545273173317)\n",
      "('Training Accuracy : ', 0.24)\n",
      "('Validation Loss : ', 2.4191550319464024)\n",
      "('Validation Accuracy : ', 0.2678)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 23, ' / ', 100, ' Total_Loss: ', 2.6851120606791654, ', Loss : ', 2.3958188639928313)\n",
      "('Training Accuracy : ', 0.24)\n",
      "('Validation Loss : ', 2.4133969731597533)\n",
      "('Validation Accuracy : ', 0.2695)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 24, ' / ', 100, ' Total_Loss: ', 2.678141408728302, ', Loss : ', 2.3888783161221774)\n",
      "('Training Accuracy : ', 0.245)\n",
      "('Validation Loss : ', 2.408805720807219)\n",
      "('Validation Accuracy : ', 0.2717)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 25, ' / ', 100, ' Total_Loss: ', 2.6717498375081, ', Loss : ', 2.3825170741521196)\n",
      "('Training Accuracy : ', 0.245)\n",
      "('Validation Loss : ', 2.405048215626307)\n",
      "('Validation Accuracy : ', 0.2735)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 26, ' / ', 100, ' Total_Loss: ', 2.6651205219247878, ', Loss : ', 2.3759185995935908)\n",
      "('Training Accuracy : ', 0.25)\n",
      "('Validation Loss : ', 2.4005362741755216)\n",
      "('Validation Accuracy : ', 0.2739)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 27, ' / ', 100, ' Total_Loss: ', 2.6592047895306585, ', Loss : ', 2.370033318076014)\n",
      "('Training Accuracy : ', 0.255)\n",
      "('Validation Loss : ', 2.3978248741469206)\n",
      "('Validation Accuracy : ', 0.2732)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 28, ' / ', 100, ' Total_Loss: ', 2.6530785338176055, ', Loss : ', 2.3639376728525803)\n",
      "('Training Accuracy : ', 0.26)\n",
      "('Validation Loss : ', 2.392746032774835)\n",
      "('Validation Accuracy : ', 0.2743)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 29, ' / ', 100, ' Total_Loss: ', 2.6469001746073375, ', Loss : ', 2.357789814050273)\n",
      "('Training Accuracy : ', 0.265)\n",
      "('Validation Loss : ', 2.387884731980296)\n",
      "('Validation Accuracy : ', 0.2764)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 30, ' / ', 100, ' Total_Loss: ', 2.641033357985982, ', Loss : ', 2.3519534726541447)\n",
      "('Training Accuracy : ', 0.275)\n",
      "('Validation Loss : ', 2.3845920190865235)\n",
      "('Validation Accuracy : ', 0.2773)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 31, ' / ', 100, ' Total_Loss: ', 2.6348930029012587, ', Loss : ', 2.3458437006629738)\n",
      "('Training Accuracy : ', 0.265)\n",
      "('Validation Loss : ', 2.3820043562235975)\n",
      "('Validation Accuracy : ', 0.2791)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 32, ' / ', 100, ' Total_Loss: ', 2.6291777512231875, ', Loss : ', 2.340158641545989)\n",
      "('Training Accuracy : ', 0.265)\n",
      "('Validation Loss : ', 2.3787280341042125)\n",
      "('Validation Accuracy : ', 0.2794)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 33, ' / ', 100, ' Total_Loss: ', 2.62391679693729, ', Loss : ', 2.3349277517701497)\n",
      "('Training Accuracy : ', 0.265)\n",
      "('Validation Loss : ', 2.375330721547862)\n",
      "('Validation Accuracy : ', 0.2804)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 34, ' / ', 100, ' Total_Loss: ', 2.6184692709238186, ', Loss : ', 2.3295099519887312)\n",
      "('Training Accuracy : ', 0.28)\n",
      "('Validation Loss : ', 2.3741586372245527)\n",
      "('Validation Accuracy : ', 0.2815)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 35, ' / ', 100, ' Total_Loss: ', 2.612923735399654, ', Loss : ', 2.32399424091083)\n",
      "('Training Accuracy : ', 0.295)\n",
      "('Validation Loss : ', 2.3704480911666135)\n",
      "('Validation Accuracy : ', 0.2826)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 36, ' / ', 100, ' Total_Loss: ', 2.6071517867514102, ', Loss : ', 2.3182520031596825)\n",
      "('Training Accuracy : ', 0.305)\n",
      "('Validation Loss : ', 2.366175772820241)\n",
      "('Validation Accuracy : ', 0.2833)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 37, ' / ', 100, ' Total_Loss: ', 2.601604052668616, ', Loss : ', 2.312734736194984)\n",
      "('Training Accuracy : ', 0.315)\n",
      "('Validation Loss : ', 2.363826376976355)\n",
      "('Validation Accuracy : ', 0.2822)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 38, ' / ', 100, ' Total_Loss: ', 2.596287570806075, ', Loss : ', 2.307448755351319)\n",
      "('Training Accuracy : ', 0.295)\n",
      "('Validation Loss : ', 2.3609578763631838)\n",
      "('Validation Accuracy : ', 0.2836)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 39, ' / ', 100, ' Total_Loss: ', 2.5909439019479783, ', Loss : ', 2.3021352176951804)\n",
      "('Training Accuracy : ', 0.295)\n",
      "('Validation Loss : ', 2.358537785572201)\n",
      "('Validation Accuracy : ', 0.2852)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 40, ' / ', 100, ' Total_Loss: ', 2.5855723267967097, ', Loss : ', 2.296793414374155)\n",
      "('Training Accuracy : ', 0.295)\n",
      "('Validation Loss : ', 2.3554407059854907)\n",
      "('Validation Accuracy : ', 0.2853)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 41, ' / ', 100, ' Total_Loss: ', 2.5804560852887812, ', Loss : ', 2.2917066439804366)\n",
      "('Training Accuracy : ', 0.295)\n",
      "('Validation Loss : ', 2.3543927433310645)\n",
      "('Validation Accuracy : ', 0.2869)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 42, ' / ', 100, ' Total_Loss: ', 2.5754509725804087, ', Loss : ', 2.2867307271489308)\n",
      "('Training Accuracy : ', 0.29)\n",
      "('Validation Loss : ', 2.350526608738765)\n",
      "('Validation Accuracy : ', 0.2872)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 43, ' / ', 100, ' Total_Loss: ', 2.5706454998495984, ', Loss : ', 2.281953913242653)\n",
      "('Training Accuracy : ', 0.3)\n",
      "('Validation Loss : ', 2.348169366647976)\n",
      "('Validation Accuracy : ', 0.2862)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 44, ' / ', 100, ' Total_Loss: ', 2.565853840604323, ', Loss : ', 2.2771914155798436)\n",
      "('Training Accuracy : ', 0.31)\n",
      "('Validation Loss : ', 2.3449156656710133)\n",
      "('Validation Accuracy : ', 0.2862)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 45, ' / ', 100, ' Total_Loss: ', 2.5611174830212313, ', Loss : ', 2.2724843929487037)\n",
      "('Training Accuracy : ', 0.3)\n",
      "('Validation Loss : ', 2.341977335694449)\n",
      "('Validation Accuracy : ', 0.2896)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 46, ' / ', 100, ' Total_Loss: ', 2.5566881902686736, ', Loss : ', 2.2680842542702964)\n",
      "('Training Accuracy : ', 0.305)\n",
      "('Validation Loss : ', 2.3404568156703935)\n",
      "('Validation Accuracy : ', 0.2906)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 47, ' / ', 100, ' Total_Loss: ', 2.5519608085754877, ', Loss : ', 2.2633864024695054)\n",
      "('Training Accuracy : ', 0.315)\n",
      "('Validation Loss : ', 2.3381377875957297)\n",
      "('Validation Accuracy : ', 0.2905)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 48, ' / ', 100, ' Total_Loss: ', 2.5471939819734093, ', Loss : ', 2.2586491385090253)\n",
      "('Training Accuracy : ', 0.32)\n",
      "('Validation Loss : ', 2.334832815703045)\n",
      "('Validation Accuracy : ', 0.2922)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 49, ' / ', 100, ' Total_Loss: ', 2.542661915417118, ', Loss : ', 2.254146539225458)\n",
      "('Training Accuracy : ', 0.315)\n",
      "('Validation Loss : ', 2.3319030104554157)\n",
      "('Validation Accuracy : ', 0.2939)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 50, ' / ', 100, ' Total_Loss: ', 2.5383505759307137, ', Loss : ', 2.2498639416079)\n",
      "('Training Accuracy : ', 0.325)\n",
      "('Validation Loss : ', 2.3302614516104247)\n",
      "('Validation Accuracy : ', 0.2933)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 51, ' / ', 100, ' Total_Loss: ', 2.533839195696496, ', Loss : ', 2.245381028725104)\n",
      "('Training Accuracy : ', 0.34)\n",
      "('Validation Loss : ', 2.3280177223333616)\n",
      "('Validation Accuracy : ', 0.2956)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 52, ' / ', 100, ' Total_Loss: ', 2.5294382840958214, ', Loss : ', 2.241008785698652)\n",
      "('Training Accuracy : ', 0.34)\n",
      "('Validation Loss : ', 2.325570864012252)\n",
      "('Validation Accuracy : ', 0.2951)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 53, ' / ', 100, ' Total_Loss: ', 2.5251562864150983, ', Loss : ', 2.2367556515737474)\n",
      "('Training Accuracy : ', 0.34)\n",
      "('Validation Loss : ', 2.323406312661776)\n",
      "('Validation Accuracy : ', 0.2949)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 54, ' / ', 100, ' Total_Loss: ', 2.520573982285017, ', Loss : ', 2.2322021318194594)\n",
      "('Training Accuracy : ', 0.34)\n",
      "('Validation Loss : ', 2.32167013418227)\n",
      "('Validation Accuracy : ', 0.2958)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 55, ' / ', 100, ' Total_Loss: ', 2.5164707060889655, ', Loss : ', 2.2281277810787645)\n",
      "('Training Accuracy : ', 0.335)\n",
      "('Validation Loss : ', 2.3184581439549743)\n",
      "('Validation Accuracy : ', 0.2961)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 56, ' / ', 100, ' Total_Loss: ', 2.5120771278565655, ', Loss : ', 2.2237628576554056)\n",
      "('Training Accuracy : ', 0.345)\n",
      "('Validation Loss : ', 2.317018436559927)\n",
      "('Validation Accuracy : ', 0.2968)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 57, ' / ', 100, ' Total_Loss: ', 2.5077625879021057, ', Loss : ', 2.219476254866383)\n",
      "('Training Accuracy : ', 0.345)\n",
      "('Validation Loss : ', 2.315346691026615)\n",
      "('Validation Accuracy : ', 0.298)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 58, ' / ', 100, ' Total_Loss: ', 2.50368896303878, ', Loss : ', 2.215430420715934)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.3139022186580127)\n",
      "('Validation Accuracy : ', 0.2988)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 59, ' / ', 100, ' Total_Loss: ', 2.4992471647937267, ', Loss : ', 2.2110164678513664)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.3115833714267255)\n",
      "('Validation Accuracy : ', 0.299)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 60, ' / ', 100, ' Total_Loss: ', 2.494926879846344, ', Loss : ', 2.206723553569837)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.309414651631889)\n",
      "('Validation Accuracy : ', 0.3006)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 61, ' / ', 100, ' Total_Loss: ', 2.4908987993989826, ', Loss : ', 2.202722726285225)\n",
      "('Training Accuracy : ', 0.345)\n",
      "('Validation Loss : ', 2.305944552308221)\n",
      "('Validation Accuracy : ', 0.3014)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 62, ' / ', 100, ' Total_Loss: ', 2.48686325571392, ', Loss : ', 2.1987143157450735)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.3044904881282835)\n",
      "('Validation Accuracy : ', 0.3019)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 63, ' / ', 100, ' Total_Loss: ', 2.4827324802204633, ', Loss : ', 2.1946105972806076)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.3035195612531676)\n",
      "('Validation Accuracy : ', 0.3024)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 64, ' / ', 100, ' Total_Loss: ', 2.4787906592501034, ', Loss : ', 2.1906960355019436)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.3007624501638193)\n",
      "('Validation Accuracy : ', 0.3021)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 65, ' / ', 100, ' Total_Loss: ', 2.4747418963821657, ', Loss : ', 2.1866744922042276)\n",
      "('Training Accuracy : ', 0.365)\n",
      "('Validation Loss : ', 2.2982676700836575)\n",
      "('Validation Accuracy : ', 0.3029)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 66, ' / ', 100, ' Total_Loss: ', 2.4705643893994984, ', Loss : ', 2.18252435985213)\n",
      "('Training Accuracy : ', 0.365)\n",
      "('Validation Loss : ', 2.296165364207325)\n",
      "('Validation Accuracy : ', 0.303)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 67, ' / ', 100, ' Total_Loss: ', 2.466368277134533, ', Loss : ', 2.1783554745470695)\n",
      "('Training Accuracy : ', 0.365)\n",
      "('Validation Loss : ', 2.2941478917534983)\n",
      "('Validation Accuracy : ', 0.3031)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 68, ' / ', 100, ' Total_Loss: ', 2.462724876752812, ', Loss : ', 2.1747392941763906)\n",
      "('Training Accuracy : ', 0.36)\n",
      "('Validation Loss : ', 2.2922303306068366)\n",
      "('Validation Accuracy : ', 0.3031)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 69, ' / ', 100, ' Total_Loss: ', 2.4584495232622645, ', Loss : ', 2.1704903684868397)\n",
      "('Training Accuracy : ', 0.365)\n",
      "('Validation Loss : ', 2.2901604667381235)\n",
      "('Validation Accuracy : ', 0.3044)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 70, ' / ', 100, ' Total_Loss: ', 2.4545803753563478, ', Loss : ', 2.1666472572020834)\n",
      "('Training Accuracy : ', 0.375)\n",
      "('Validation Loss : ', 2.2877552161705275)\n",
      "('Validation Accuracy : ', 0.3053)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 71, ' / ', 100, ' Total_Loss: ', 2.4340101333822015, ', Loss : ', 2.146095264199778)\n",
      "('Training Accuracy : ', 0.36)\n",
      "('Validation Loss : ', 2.2684180594254117)\n",
      "('Validation Accuracy : ', 0.3136)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 72, ' / ', 100, ' Total_Loss: ', 2.430802130784301, ', Loss : ', 2.1428970442794815)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2678279378469464)\n",
      "('Validation Accuracy : ', 0.314)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 73, ' / ', 100, ' Total_Loss: ', 2.428650176714779, ', Loss : ', 2.1407544902282196)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2668871006321907)\n",
      "('Validation Accuracy : ', 0.3141)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 74, ' / ', 100, ' Total_Loss: ', 2.4265785825080126, ', Loss : ', 2.138692265555656)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2659972558125774)\n",
      "('Validation Accuracy : ', 0.3143)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 75, ' / ', 100, ' Total_Loss: ', 2.4245943650545194, ', Loss : ', 2.1367173822423946)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.265112646031486)\n",
      "('Validation Accuracy : ', 0.3145)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 76, ' / ', 100, ' Total_Loss: ', 2.422539628359014, ', Loss : ', 2.1346718655814287)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.264526005283492)\n",
      "('Validation Accuracy : ', 0.3141)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 77, ' / ', 100, ' Total_Loss: ', 2.42061049218575, ', Loss : ', 2.1327518768908673)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.263943722972322)\n",
      "('Validation Accuracy : ', 0.3147)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 78, ' / ', 100, ' Total_Loss: ', 2.418520470859194, ', Loss : ', 2.130671108894436)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.263235727976829)\n",
      "('Validation Accuracy : ', 0.3147)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 79, ' / ', 100, ' Total_Loss: ', 2.416581175773727, ', Loss : ', 2.1287409497801364)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2622962043169146)\n",
      "('Validation Accuracy : ', 0.3153)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 80, ' / ', 100, ' Total_Loss: ', 2.4146478429762697, ', Loss : ', 2.1268167544863767)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.261592968748746)\n",
      "('Validation Accuracy : ', 0.3162)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 81, ' / ', 100, ' Total_Loss: ', 2.412722834299252, ', Loss : ', 2.124900886484562)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2606010141599135)\n",
      "('Validation Accuracy : ', 0.3161)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 82, ' / ', 100, ' Total_Loss: ', 2.4106944420489786, ', Loss : ', 2.1228815702760153)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.259990858740071)\n",
      "('Validation Accuracy : ', 0.3169)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 83, ' / ', 100, ' Total_Loss: ', 2.408836723462222, ', Loss : ', 2.1210329183400405)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.259119670565759)\n",
      "('Validation Accuracy : ', 0.3176)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 84, ' / ', 100, ' Total_Loss: ', 2.406838741749275, ', Loss : ', 2.119043813620321)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2583827090771544)\n",
      "('Validation Accuracy : ', 0.3182)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 85, ' / ', 100, ' Total_Loss: ', 2.4047870704745646, ', Loss : ', 2.117001031460621)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2576153230964975)\n",
      "('Validation Accuracy : ', 0.3178)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 86, ' / ', 100, ' Total_Loss: ', 2.4028590495539426, ', Loss : ', 2.1150818512456397)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.2570016035525)\n",
      "('Validation Accuracy : ', 0.3178)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 87, ' / ', 100, ' Total_Loss: ', 2.400892715899329, ', Loss : ', 2.1131243511170523)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.256405386471184)\n",
      "('Validation Accuracy : ', 0.3186)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 88, ' / ', 100, ' Total_Loss: ', 2.3989976142396774, ', Loss : ', 2.111237920496889)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.2557486527721347)\n",
      "('Validation Accuracy : ', 0.3189)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 89, ' / ', 100, ' Total_Loss: ', 2.3969649537871245, ', Loss : ', 2.1092139640579988)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.2549372764362574)\n",
      "('Validation Accuracy : ', 0.3197)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 90, ' / ', 100, ' Total_Loss: ', 2.395050174001957, ', Loss : ', 2.107307776153435)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.254316693134303)\n",
      "('Validation Accuracy : ', 0.3192)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 91, ' / ', 100, ' Total_Loss: ', 2.393009233025523, ', Loss : ', 2.105275446672325)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.2538314184085673)\n",
      "('Validation Accuracy : ', 0.3208)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 92, ' / ', 100, ' Total_Loss: ', 2.3910945865701123, ', Loss : ', 2.1033694041409845)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.2527797920579626)\n",
      "('Validation Accuracy : ', 0.3205)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 93, ' / ', 100, ' Total_Loss: ', 2.389090738115169, ', Loss : ', 2.101374064743614)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.2522898013478594)\n",
      "('Validation Accuracy : ', 0.3204)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 94, ' / ', 100, ' Total_Loss: ', 2.387052900231386, ', Loss : ', 2.0993447785595416)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.251621123399221)\n",
      "('Validation Accuracy : ', 0.3205)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 95, ' / ', 100, ' Total_Loss: ', 2.3850941864487107, ', Loss : ', 2.0973946639213885)\n",
      "('Training Accuracy : ', 0.355)\n",
      "('Validation Loss : ', 2.251028926900446)\n",
      "('Validation Accuracy : ', 0.3198)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 96, ' / ', 100, ' Total_Loss: ', 2.383115426739292, ', Loss : ', 2.095424388534433)\n",
      "('Training Accuracy : ', 0.35)\n",
      "('Validation Loss : ', 2.2501419449774507)\n",
      "('Validation Accuracy : ', 0.3208)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 97, ' / ', 100, ' Total_Loss: ', 2.3811133258983745, ', Loss : ', 2.093430633635806)\n",
      "('Training Accuracy : ', 0.36)\n",
      "('Validation Loss : ', 2.249360784122972)\n",
      "('Validation Accuracy : ', 0.3215)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 98, ' / ', 100, ' Total_Loss: ', 2.379219692481207, ', Loss : ', 2.091545250445843)\n",
      "('Training Accuracy : ', 0.36)\n",
      "('Validation Loss : ', 2.249038353530934)\n",
      "('Validation Accuracy : ', 0.3212)\n",
      "-----------------------------------------------------------------------\n",
      "('Epoch', 99, ' / ', 100, ' Total_Loss: ', 2.377315513118594, ', Loss : ', 2.0896494055722457)\n",
      "('Training Accuracy : ', 0.36)\n",
      "('Validation Loss : ', 2.2482084037580896)\n",
      "('Validation Accuracy : ', 0.3208)\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Initializing Momentum,Accum for ADAM\n",
    "momentum = 0\n",
    "accum = 0\n",
    "\n",
    "#Initializing values to obtain best accuracy while training\n",
    "max_acc = 0\n",
    "Val_acc = 1e-3\n",
    "\n",
    "#Initializing Needed arrays and values for the training\n",
    "Examples = xtr.shape[0]\n",
    "valid_examples = xval.shape[0]\n",
    "w = []\n",
    "b = []\n",
    "Total_Training_Losses = []\n",
    "Total_Validation_Losses = []\n",
    "minimum_w = []\n",
    "minimum_b = []\n",
    "Loss_Per_Epoch_Total = []\n",
    "Loss_Per_Epoch = []\n",
    "scores = []\n",
    "\n",
    "#Initializing Weights\n",
    "w,b = XavierInit(layers)\n",
    "    \n",
    "for qq in range(Epochs):\n",
    "    Loss_Per_iter_total = []\n",
    "    Loss_Per_iter = []\n",
    "    for E in range(int(math.floor(Examples/MiniBatchSize))):\n",
    "        reg_loss = 0\n",
    "        #Forward Passing and Finding Softmax Function Call\n",
    "        scores,layers_step = FwdPass(w,b,layers,E,xtr,MiniBatchSize)\n",
    "        loss,probability = SoftmaxFn(scores,ytr[E*MiniBatchSize:(E+1)*MiniBatchSize])\n",
    "        #Calculating Regularization Loss and Adding to loss\n",
    "        for j in range(len(w)):\n",
    "            reg_loss += 0.5*reg*np.sum(w[j]*w[j])\n",
    "        total_loss = loss + reg_loss\n",
    "        #Adding Losses to be able to draw graph at the end\n",
    "        Loss_Per_iter_total.append(np.mean(total_loss,dtype=np.float64))\n",
    "        Loss_Per_iter.append(np.mean(loss,dtype=np.float64))\n",
    "        #Backward Pass Using Analytic Graph\n",
    "        dw,db = BackwdPass(E,layers,layers_step,probability,ytr,Examples, w, MiniBatchSize)\n",
    "        dw = np.array(dw)\n",
    "\n",
    "        #Swapping because of difference in orders\n",
    "        swap_range = int(math.floor(len(dw)/2))\n",
    "        for j in range(swap_range):\n",
    "            dw[j],dw[len(dw)-1-j] = dw[len(dw)-1-j],dw[j]\n",
    "            db[j],db[len(dw)-1-j] = db[len(dw)-1-j],db[j]\n",
    "        \n",
    "        #Regularizing the Gradient\n",
    "        for q in range(len(w)):\n",
    "            dw[q] += reg * w[q]\n",
    "\n",
    "        #Updating Weights, Biases, Momentum and Accum [Loops are there because of Problems in Shapes and Data Structure]\n",
    "        momentum = (1-beta1)*dw + beta1*momentum\n",
    "        accum = (1-beta2)*(dw*dw) + beta2*accum\n",
    "        accum_s = accum\n",
    "        for q in range(len(accum)):\n",
    "            accum_s[q] = np.sqrt(accum_s[q],dtype=np.float64)\n",
    "            \n",
    "        w += -learn_rate * momentum / (accum_s + 1e-7)\n",
    "        for q in range(len(db)):\n",
    "            db[q] = np.reshape(db[q],(db[q].shape[1]))\n",
    "            b[q] += -learn_rate*db[q]\n",
    "        \n",
    "        #Saving the Best W's and B's for the highest accuracy so far\n",
    "        if(Val_acc > max_acc):\n",
    "            minimum_w = w\n",
    "            minimum_b = b\n",
    "            max_acc = Val_acc\n",
    "            \n",
    "    if(qq == 70):\n",
    "        learn_rate *= 0.5\n",
    "\n",
    "        \n",
    "    #Calculating Losses and Accuracies for Training and Validation\n",
    "    Loss_Per_Epoch.append(np.mean(Loss_Per_iter))\n",
    "    Loss_Per_Epoch_Total.append(np.mean(Loss_Per_iter_total))\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print(\"Epoch\", qq, \" / \" , Epochs , \" Total_Loss: \" , Loss_Per_Epoch_Total[qq] , \", Loss : \", Loss_Per_Epoch[qq]) \n",
    "    #Validation Set\n",
    "    print (\"Training Accuracy : \" , (np.mean(predicted_class == ytr[E*MiniBatchSize:(E+1)*MiniBatchSize])) )\n",
    "    scores_valid, layers_valid = FwdPass(minimum_w,minimum_b,layers,0,xval,valid_examples)\n",
    "    predicted_class_v = np.argmax(scores_valid, axis=1)\n",
    "    valid_loss,valid_prob = SoftmaxFn(scores_valid,yval)\n",
    "    Val_acc = (np.mean(predicted_class_v == yval))\n",
    "    print (\"Validation Loss : \" , (np.mean(valid_loss)))\n",
    "    print (\"Validation Accuracy : \", Val_acc)\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "    Total_Training_Losses.append(Loss_Per_Epoch[qq])\n",
    "    Total_Validation_Losses.append((np.mean(valid_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy: ', 0.3157)\n",
      "('Class ', 1, 'Accuracy is', 164.0, '/500', ', Accuracy = ', 0.328)\n",
      "('Class ', 2, 'Accuracy is', 124.0, '/500', ', Accuracy = ', 0.248)\n",
      "('Class ', 3, 'Accuracy is', 273.0, '/500', ', Accuracy = ', 0.546)\n",
      "('Class ', 4, 'Accuracy is', 131.0, '/500', ', Accuracy = ', 0.262)\n",
      "('Class ', 5, 'Accuracy is', 224.0, '/500', ', Accuracy = ', 0.448)\n",
      "('Class ', 6, 'Accuracy is', 122.0, '/500', ', Accuracy = ', 0.244)\n",
      "('Class ', 7, 'Accuracy is', 177.0, '/500', ', Accuracy = ', 0.354)\n",
      "('Class ', 8, 'Accuracy is', 245.0, '/500', ', Accuracy = ', 0.49)\n",
      "('Class ', 9, 'Accuracy is', 81.0, '/500', ', Accuracy = ', 0.162)\n",
      "('Class ', 10, 'Accuracy is', 253.0, '/500', ', Accuracy = ', 0.506)\n",
      "('Class ', 11, 'Accuracy is', 264.0, '/500', ', Accuracy = ', 0.528)\n",
      "('Class ', 12, 'Accuracy is', 109.0, '/500', ', Accuracy = ', 0.218)\n",
      "('Class ', 13, 'Accuracy is', 113.0, '/500', ', Accuracy = ', 0.226)\n",
      "('Class ', 14, 'Accuracy is', 34.0, '/500', ', Accuracy = ', 0.068)\n",
      "('Class ', 15, 'Accuracy is', 181.0, '/500', ', Accuracy = ', 0.362)\n",
      "('Class ', 16, 'Accuracy is', 44.0, '/500', ', Accuracy = ', 0.088)\n",
      "('Class ', 17, 'Accuracy is', 39.0, '/500', ', Accuracy = ', 0.078)\n",
      "('Class ', 18, 'Accuracy is', 306.0, '/500', ', Accuracy = ', 0.612)\n",
      "('Class ', 19, 'Accuracy is', 126.0, '/500', ', Accuracy = ', 0.252)\n",
      "('Class ', 20, 'Accuracy is', 147.0, '/500', ', Accuracy = ', 0.294)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XXWd//HXJ22TtrTN1jZt030v3VtowYKUQSwggqII\n8kNRmZ/rTxg3ZBy1MI4zqA9FcJtRmQoqgriwOCAiEJROKUtbutA1XeiWtGmS7lmafH5/nHOT23Bv\ncpvmnps07+fjcR733nPPPeebPG77znc95u6IiIgkkpXpAoiISOelkBARkaQUEiIikpRCQkREklJI\niIhIUgoJERFJSiEh3ZqZLTazX3bAeS4ws/UdUSaRzkQhIZ2KmV1vZi+Z2REzKzOzZWb2qTRfNuXJ\nQmbWaGaHzexQ+FgJ4O4vuvuU9lw8DKoH2jhmu5kdC6+7x8yWmFnf9lxP5FQoJKTTMLMvAHcD3wKK\n3H0I8EngbWbWK8lnov4OOzDD3Qe4e393L2jrA2bWo4Ou+y53HwDMAmYD/9wB5xVplUJCOgUzGwDc\nCXzK3f/o7kcB3P11d/+Qu9eHxy0xsx+b2f+Y2WFgoZldYWYrzOygme0ws8Vx5x0V/vX/f81sd7h9\nocXlc8zs/vCv9DVmNqe1ooZby/JfZGY7415vM7PbzOx14IiZZZnZl81sV3id9WZ2sZktAr4CXBfW\nTFa2cW3cfR/wNEFYxK73vJl9LO71TWb297jXjWb2CTPbZGaVZvbDVq4j0kQhIZ3F+UA28HgKx34Q\n+Ia79wdeBI4AH3L3XOBdwCfN7KoWn1kIjAMWAV82s3+Ie+/dwINALvAE8KN2/gwtm62uBy4H8oDx\nwGeAuWFtYBGw3d2fBv4deDismcxu6yJmNjw87+ZTLM+7gLnATOADZvbOtq4lopCQzmIgUOHujbEd\nZrbUzKrCtvgL4o59zN1fAnD3Onf/m7uvC1+vBR4CLmpx/jvcvSZ8fwlB0MS86O5Pe7CQ2S+BGW2U\ndUVYrkoz+34rx93j7nvcvRZoIAjBaWbW093fdPdtbVynpUfN7BDwJlAO3HGKn/8Pdz/s7juB54mr\niYgko5CQzuIAMDC+j8HdF7h7fvhe/Hd1Z/wHzWyemT1nZvvMrBr4BEHoNJ0K2BX3egcwLO51Wdzz\nY0DvNvo6Zrt7vrsXuPs/tXJc0zXdvRT4J4L/2MvN7EEzG9LKZxO5OqyFXARM5uSfMRXlcc+PAf1O\n8fPSDSkkpLNYBtQCV6dwbMtmlAeBR4Fid88D/ouT+w0MGBH3eiSwp/1FfWufRBInldPdH3L3C4FR\n4a5vJTqureu6+9+B+4Hvxr13FIgf7XSqASSSkEJCOgV3Pwj8K/BjM3ufmfWzwCxO/s8vkX5AlbvX\nm9k84IYEx3zNzPqY2VTgowRNUsmkGgIpM7OJYUd1NlAHHAdiTWvlwGgzO5Xrfh+41Mymh69XAdeE\nP+N44OaOKrt0bwoJ6TTc/TvA54HbCJqAyoCfhK//t5WPfhr4hpkdBL4KPJzgmBeALcAzwLfd/dnW\nitLO91o7Lge4C9hPUIsZRPMQ1kcIgumAmb2ayvncvYKgNvH1cNfdQD3B72wJ8Ks2yqMbyUhKLIqb\nDoXtu68Cu9z9qhbvZQMPEIy6qACuc/c3014o6RbMbBSwFegV3ykuIqmJqiZxK/BGkvduBirdfQJB\nFfrbEZVJuo8Obz4S6S7SHhLhmO4rgJ8nOeRqgmozwO+AS9JdJul21LQi0k5R1CTuBr5E8n+oxYRD\nGt29Aag2szaXOhBJhbvvcPceamoSaZ+0hoSZvQsod/dVJFnOINHH0lkmERFJXc80n38BcJWZXQH0\nAfqb2QPu/uG4Y3YRjGHfEy6ENsDdK1ueyMzUZCAi0g7u3u4/vtNak3D3r7j7SHcfS7COzXMtAgKC\ntXJuCp9fCzzXyvm0ubN48eKMl6GzbPpd6Heh30Xr2+nKyDwJM7vTzK4MX95HsBzDZoJlC27PRJlE\nROSt0t3c1MTdXyCY0IS7L47bXwt8IKpyiIhI6jTjugtauHBhpovQaeh30Uy/i2b6XXScSGZcdwQz\n865SVhGRzsLM8M7acS0iIl2bQkJERJJSSIiISFIKCRERSUohISIiSSkkREQkKYWEiIgkpZAQEZGk\nFBIiIpKUQkJERJJSSIiISFIKCRERSUohISIiSSkkREQkKYWEiIgk1aVCoqGxIdNFEBHpVrpUSNQ1\n1GW6CCIi3YpCQkREklJIiIhIUgoJERFJqkuFRG1DbaaLICLSrXSpkFBNQkQkWgoJERFJqkuFRO0J\nNTeJiESpS4WEahIiItFSSIiISFIKCRERSapLhYSGwIqIRKtLhYRqEiIi0VJIiIhIUgoJERFJqkuF\nhOZJiIhEq0uFhGoSIiLRUkiIiEhSXSokNARWRCRaXSokVJMQEYmWQkJERJJSSIiISFJdKiQ0BFZE\nJFpdKiRUkxARiVbXColGhYSISJS6VEiouUlEJFpdKiTU3CQiEi2FhIiIJKWQEBGRpNIaEmaWY2bL\nzWylma0xs8UJjrnJzPaZ2Ypw+1iy82lZDhGRaPVM58ndvdbMLnb3Y2bWA1hqZk+5+8stDn3I3W9p\n63yqSYiIRKvNmoSZjTaz7PD5BWb2aTMbkOoF3P1Y+DSHIJQ80WVSOZdCQkQkWqk0Nz0KuJmNA5YA\nE4AHU72AmWWZ2UqgDHjG3V9JcNg1ZrbKzH5rZsOTnUtDYEVEopVKc1Oju9eb2TXAD9z93vA//ZS4\neyMwO6x9PGpmZ7v7G3GHPA48GF7j48D9wCWJzrXniT3cUX4HAAsXLmThwoWpFkNEpFsoKSmhpKSk\nw85n7olaf+IOMHsZ+A7wNeA97r7VzNa6+7RTvpjZ14Cj7v69JO9nAZXunpfgPR/z/TFsvXXrqV5W\nRKTbMjPcPaUm/URSaW76GHAx8O0wIMYAv0mxcAPNLDd83ge4FNjQ4pghcS+vBuJrGSdRn4SISLTa\nbG5y97XApwHC//D7uPs3Uzz/UOD+sIaQBTzs7k+a2Z3AK+7+J+AWM7sKqAcqgY8kO5mGwIqIRCuV\n5qZngfcCPYAVBP+RP+fuX0p/8U4qhw/4jwEcvP1glJcVEenSomhuKnD3Q8A1wK/cfS6wqL0XPB1q\nbhIRiVYqIdHTzAYB1wJPpLk8rao9UUtbNR8REek4qYTEN4EXgJ3u/rKZjQW2pbdYiWVZFg3ekIlL\ni4h0S6l0XD8EPBT3eivBKKTIZffIpq6hjp5ZaV1NREREQqksyzEsnAm9N9weNrNhURSupVhIiIhI\nNFJpbloCPAOMDrdnwn2Ry+6RraU5REQilEpIFLn7z9y9Ntx+DhSlu2CJ5PTMUU1CRCRCqYREpZld\nb82uI5grETk1N4mIRCvVZTk+DFQA+4EPAR9NZ6GSye6RrVnXIiIRajMk3H27u1/h7oXuPtDdrwTe\nHUHZ3iKnh5qbRESi1N7bl97WoaVIkZqbRESi1d6QaPc6IKdDISEiEq32hkRG1sbQEFgRkWglnbps\nZlUkvx91/7SVqBUaAisiEq3W1rcYGFkpUqTmJhGRaCUNCffOt5KehsCKiESrvX0SGaGahIhItLpU\nSGiehIhItLpUSKgmISISrVSWCr/azNab2UEzO2Rmh83sUBSFa0lDYEVEopXK3Xu+C7zX3dekuzBt\nUXOTiEi0UmluKu8MAQFqbhIRiVoqNYlXzOzXwKNAU1uPuz+etlIloSGwIiLRSiUkCoFG4Kq4fQ5k\nJCQO1h6M+rIiIt1WmyHh7h+KoiCpyOmZQ90xNTeJiEQlldFNw8zsETPbG24Pm9mwKArXkvokRESi\nlUrH9RLgL8DocHsm3Bc5DYEVEYlWKiFR5O4/c/facPs5UJTugiWS0yOHukbVJEREopJKSFSa2fXW\n7DqgMt0FS0TNTSIi0UolJD4GfBioAPYDHwr3RU7NTSIi0UpldNN24Ir0F6VtqkmIiESrtTvTfcHd\nv2tmd5PgDnXu/vm0liwB3ZlORCRardUkSsPHtVEUJBWqSYiIRKu1O9M9Gj6tcvc/xL9nZtektVRJ\naFkOEZFopdJx/dUE+/6lowuSCq0CKyISrdb6JBYBlwHFZva9uLcGEKzlFDk1N4mIRKu1Pol9BP0R\nNcC6uP2HgdvTWahkFBIiItFqrU9iJbDSzH7t7jURlikpzZMQEYlWKkuFF5vZN4Gzgd6xne4+MW2l\nSkJDYEVEopVKx/UvCBb0M+By4LfAw2ksU1JqbhIRiVYqIdHX3Z8GcPdSd/8qQVhETkNgRUSilUpz\nU62ZZQGlZvZJYDfQP73FSkxDYEVEopVKSHwOOAu4BfgmkEuGFvjr1aMXdQ11uDtmlokiiIh0K6ks\n8Lc8fHqYYAXYjMmyLHpm9eRE4wl69eiVyaKIiHQLrU2m+yMJFvaLcfeMLs2hkBARSb/WahI/DB+v\nBoYBvw5ffxDYk85CtUb9EiIi0WltMt2zAGb2LXc/J7bfzB4FXo6gbAlpGKyISHRSGQLbz8xGx70e\nCfRL5eRmlmNmy81spZmtMbPFCY7JNrOHzGyzmS0zs5GtnVOzrkVEopPK6KYvAH83s40EE+rGA59K\n5eTuXmtmF7v7MTPrASw1s6fcPb4mcjNQ6e4Twvtnfxu4Ptk5NetaRCQ6qYxu+h8zm0iwLAfAG+5+\nPNULuPux8GlOeL2WneFXA7Eaxu9o7gtJSM1NIiLRaW1000Xu/oKZXdXirWIzw90fT+UC4US814Bx\nwI/c/ZWW5wN2Arh7g5lVm1mBu1cmOp9CQkQkOq3VJC4FXgCuTfCeAymFhLs3ArPNbADwqJmd7e5v\ntPKRpLPk7rjjDvat2MePNv6IG6+6kYULF6ZSBBGRbqOkpISSkpIOO5+5J50K0eHM7GvAUXf/Xty+\np4A73H152G+x190HJ/isuztvX/J2/u0f/o23j3p7ZOUWEemqwpafdi9R0Vpz0y2tfdDd723r5GY2\nEKh394Nm1oegdnJXi8OeAG4ClhPUWp5r7ZxqbhIRiU5rzU2DOuD8Q4H7w36JLOBhd3/SzO4EXnH3\nPwH3Ab80s83AAVoZ2QQaAisiEqXWJtN97XRP7u5rgDkJ9i+Oe14LfCDVc2oIrIhIdNocAmtmOcBH\ngKmcfGe6j6evWMmpuUlEJDqpzLh+ABgNXEnQbzAOyNg9rxUSIiLRSSUkJrr7PwNH3P0+4DJgXnqL\nlVx2lu5OJyISlVRCoj58rDazKQR3pXvLENWoqE9CRCQ6qazddJ+Z5RMsnfE00Bf4elpL1Qo1N4mI\nRKe1eRKD3H2/u/9XuOt5ghVgM0pDYEVEotNac9NaM/uzmd1kZv0jK1EbdNMhEZHotBYSxcAPgHcA\npWb2ezN7fzgkNmPU3CQiEp2kIeHuJ9z9f9z9QwTNTA8C1wE7zOz+qArYkkJCRCQ6qYxuwt1rgBXA\nSqAamJ3OQrUmu4eGwIqIRKXVkDCzYWb2OTN7GXiGYGTT+919RiSlS0BDYEVEotPa6Ka/AWOA3wOf\ndfflkZWqFWpuEhGJTmvzJH4IPOPuVVEVJhVqbhIRiU5rITEB+LSZAfwVeMrdX4ukVK1QTUJEJDqt\njW76prsvBN4DbCQIjFVm9oCZ3WBmhVEVMp7mSYiIRKfNZTncvRp4JNwwsxnA5cDDBHMoIqWahIhI\ndFK5n0SikUwPAd/p+OK0TctyiIhEJ6UF/oBZwDrAgCnAG0B/M/u4uz+bxvK9hYbAiohEJ5XJdNuB\nue4+y91nAnOBTcAi4LtpLFtCam4SEYlOKiExxd1Xx16E960+2923pK9YyWkIrIhIdFJpbtpgZj8g\n6IeAYP2mDeFCfyfSVrIkVJMQEYlOKjWJDwO7gNvDbQ9wE0FAXJK+oiWmIbAiItFJZQjsMeBb4dbS\nwQ4vURtUkxARiU4qQ2DPI7h16aj44919YhrLlZSGwIqIRCeVPoklwG3Aa0BDeovTNg2BFRGJTioh\nccjdn0h7SVJx+DDZOWpuEhGJSiod18+Z2X+Y2blmNiO2pb1kifzkJxoCKyISIXP31g8w+3uC3e7u\nb09PkZKWw33IELy0lKzvnEXD1xvIspRurCci0m2ZGe5u7f18KqObLmzvyTvcvHnYkiVk98imvqGe\nnJ45mS6RiMgZLWlNwsw+6O6/MbNbEr3v7vemtWRvLY/7Sy/BBz7A3Ntyue2if+G6addFWQQRkS4n\nnTWJ/PBxUHtP3uHmz4cJE3ik7m287c+3snD0Qor6FWW6VCIiZ6w2+yQ6CzNzd4fnn4dPfpKv3fMe\n1lRv5I/X/ZHw7nkiItLC6dYkUum4Hgh8DBjNyZPpPt7ei7ZHU0i4w7XX0tCrB7MvWMdtF97OjTNu\njLIoIiJdRhQhsRR4iRaT6dz94fZetD2aQgLg+HG49FLKp41h+rinWfmJlRQPKI6yOCIiXUIUIbHK\n3We19wId5aSQAKishAsu4Pl3jOeTEzfy1w/9lRG5IzJXQBGRTuh0QyKViQZPmdk723uBtCkogD//\nmYv/uJJ7ymZz4ZIL2XRgU6ZLJSJyRkmlJlEF5ALHgDqCW5i6uxekv3gnlcMTlnXDBnjnO1l23QLe\nN+QFnvw/TzJrSMYrPiIinUIUzU09Eu1390gX+0saEgA7dsCll7Lu0lksHPUcD7z3l1w+4fIoiyci\n0imlLSTMbIK7b062TlP8LU2j0GpIAJSXw6JF7J0xlvOm/i9fXPgvfHb+Z6MroIhIJ5TOkLjP3W/u\nVGs3tTWno7oaPvIRardv4b1X1zBm3iLuvuxusntkR1NIEZFOJu3NTZ1FSiEBwTyKH/+YxjsWc+/7\nR/CrWVn8+n0PMmngpPQXUkSkk4kkJMxsMnA20Du2z90fbO9F2yPlkIhZvRq/4Qa2De7Fuy58k1vf\n/U0+MfcTmp0tIt1K2ofAmtlXgZ8C/wlcDnwfeH97LxiZGTOwV19l7LxFrPlJFlt/9m0u+/VllFaW\nZrpkIiJdRiqjm9YAs4AV7j7TzIYCv3D3RVEUMK4cp1aTiLdsGf6Rm9hSlM0N5+3mPVd+kS8t+JL6\nKkTkjBfFZLrj4XDXE2bWHygDRrX3ghlx/vnY66uZcMWNvHSfMfnb/83bvjeVJzY+QVfpkxERyYRU\nQmKlmeUB/w28Crwcbl1L795w++30WPcG1xQtZOld+9l0+z9y+U/fzqt7Xs106UREOqVWm5ss6OUd\n4u57w9fjgQHuviKi8sWXpf3NTYmsW0fj4sXUlDzDXQtg83sv5LZF32D20Nkddw0RkQyLYsb1Wnef\n1q6Tmw0HHgCKgEbgZy3vaGdmFwGPAVvDXX9w939LcK6ODYmYVas4cecdnHj2Lzwy1Vhx5Vyuv+k7\nzB8+v+OvJSISsShC4lfAd919ZTsKN4SgJrLKzPoRLDd+tbtviDvmIuAL7n5VG+dKT0jE7NlD/X0/\n49hP7mUvh3lhfhEj/u8Xeedln6FnVpu3AhcR6ZTS1nFtZrH/GWcDr5jZRjNbYWYrzSyl5iZ3L3P3\nVeHzI8B6INGNHzI/eWHYMHp9bTG5u/Yz/qG/8I6+05l/w5fYMLIvf735YnYufybTJRQRiVxry3Ks\ncPc5ZjYu0fvufkoTDsxsNFACTAsDI7b/IuB3wC5gD/Ald38jwefTW5NIpKGBLY/9gt33/4CJJWuo\n6d+HI+9cyLgb/h99L7oEevWKtjwiIqconWs3rXT3DunFDZuaSoBvuPtjCd5rdPdjZnY5cI+7T0xw\nDl+8eHHT64ULF7Jw4cKOKF5KauuO8+LvvkfFI/cz6eVSJhzsQfVF5zH4w5+i15VXwVlnRVYWEZFk\nSkpKKCkpaXp95513pi0kdgHfS/ZBd0/6Xovz9AT+BDzl7vekcPw2YK67V7bYH31NIomKYxU8UfJT\nKh5ewtxl2zlvt1F93iwKr3g/OZe8E2bMgKxURheLiKRXOmsSe4GfkKS/wN3vTLGADwAV7v75JO8X\nuXt5+Hwe8Ft3H53guE4TEvHKjpTx5LJfUv6H+xny2iYu3ZXNoKMO57+NnIWXwAUXwDnnBPM0REQi\nls6QWOHuc9pdsuAcC4C/AWsAD7evEMzYdnf/qZl9BvgUUA8cBz7n7ssTnKtThkS86ppqntz8JM+/\n9BC1LzzLFeUDuGhnDwbvqiJr/nnYxRfDxRfD3LkKDRGJRJfok+gIXSEk4tU11PHC9hd4bONj/G31\nE8zZcpQbKoZx7uaj5G0vw2bOhPPPhwsvDLbCwkwXWUTOQOkMiYKW/QKZ1NVCIp67s/HARp7a/BRP\nlz7NqtKlXHmwiPceGMy5W2sY9PoWbNQoWLAgqGXMnQvTpkG2FiAUkdOjmw51QfUN9by29zVKtpfw\n7LZneWXHMq6pGcM11cOYs9cZsnE3Wdu2w9SpQX/GuefC/PkwebI6xEXklCgkzgA1J2pY+uZSnt/+\nPCXbS1hVtor5+dO5tnY8F+7rw/itVeS8uhIqKmDevKCmMXkyTJoUPOblZfpHEJFOSiFxBjpad5Rl\nu5bx4psv8vc3/87Lu19mbP5Yrsg9lyurBjFzbyP9tu2GDRuCLS8vaJ6aNi0Yfjt7NkyZAj21nIhI\nd6eQ6AbqG+pZsXcFf9vxN17Y8QJLdy5lUN9BXDDyAi4Y/jYusjGM2X2UrLXr4PXXYeVK2LUrqGXE\nahyTJsHYsTB6NAwcCLqNq0i3oJDohhq9kXX71vHimy/y4s4XWbZzGdU11Zw/4nzOKz6P80ecz7zc\nsxmwZSds3Ni8bd8O27ZBTQ2MGwcTJwbbuHEwZAgUFcHQocGmvg+RM4JCQgDYe3gvy3Yt46VdL7Fs\n1zJW7l3J2PyxLBixgAUjF7BgxAJG543GzODQISgtDYJj0ybYuhXKy4Ntzx44ehTOPjvoOJ86NWi6\nOvtsGDlS4SHSxSgkJKH6hnpWla1i6c6lvPjmiyzduZRGb2Re8TzmDZvH/OHzmV88n9zeuW/9cFUV\nvPEGrFsXPMa2AweguBiGDw+2oqJgGzw4qInE9ufmqjlLpJNQSEhK3J1dh3bx8u6XWb57Oct3L+e1\nPa8xKm8U84vnM3foXOYMncPMITPp26tv4pMcOxb0dcS2ffuCrbwcysqCfTt3QmNjEBYjRgRbbi70\n7RssglhYCKNGNW99k1xLRDqEQkLarb6hnrX71rJ893JW7F3Bir0reGP/G4wrGMc5w87hnKHncM6w\nc5g5ZCa9e57CMiIHDzYHxq5dcPhwEDBHj8L+/bBjR9A/8uabQSf6+PEwYULQFzJwYLDFaidDh0JB\ngWomIu2kkJAOVXuilrX71vLqnld5Zc8rvLb3NTZWbGTywMmcM+wc5gydw5yhc5g+eDp9evU5vYs1\nNAQhsnkzbNkS1EgqKoItVjspK4MjR4IayKBBwTZkSNDsNWxYECh9+gRbv35Bv8nw4Rr+KxJSSEja\nHa8/zury1byy5xVW7l3JirIVbKzYyITCCZwz9BzOLT6344IjkdraIDj27w+2sjLYvTvoZK+ogOPH\ng+3w4aB2sm9fECItayaxPpNYwAwerDCRM55CQjKi9kQtq8tXN9U4VpatZGPFRsbkj2HWkFlMHzyd\n6YOnM23wNEbmjgxGVUVWuNogLOJrJrFgifWn7N0bdMQXFgbNWf37B1tubnOwDBx4ckf9kCFaT0u6\nHIWEdBq1J2p5Y/8bvF7+Omv3rWXNvjWsKV/DsfpjTC+azsyimcwomsHMoplML5qevIM8KidOBLWO\nqqqgFnL4MFRXB+ERq7ns2RP0rezcGRyblxfUUIqKYMCAIFQGDAiCprAw2AYObG4aGzhQwSIZpZCQ\nTq/iWAWry1fzetnrrN4XPG6o2MDI3JHMGjKL2UNmM3vobGYNmcXgswZnurjJNTQE4bF3bxAYhw4F\n28GDUFkZhEt8wOzfHzzv3TsIkYKCIFRi26BBzc1fQ4cGNZl+/YLHAQOCz6nDXk6TQkK6pPqGejZU\nbGBV2SpWlq1kZdlKVpWtonfP3k01jumDpzO9aDpTBk4hp2dOpovcPu5BDSUWIgcPNm/79zc3gZWV\nBccdOdJcqzlxIgiLAQOC8IgFyMCBzTWWWHNZYWHQxzJypEaDyUkUEnLGcHd2HtoZ1DjKVwfNVfvW\nsLVqK2PzxzYHx+DpzCiaEX1fR9Tq6oKwOHSoOUBitZZYX0ssfCorg6DZuTP4XHFxEC6x2knfvsEI\nsN69g32xZViGDFHT2BlOISFnvNoTtayvWM+a8jVN4bG6fDVH648ybfA0pg2axtTBU5k2eBpTB01l\n8FmDz+zwaMuhQ0FfyqFDzTWT48eDNbtqaoKgiR9iHGsaO3AgCJNY01h+/lu3vLyTX8dqMZpl32kp\nJKTbqjhWwdp9a1m3b13wuH8d6/avA2DqoKlMGTiFyQMnM2XQFKYMnMKI3BFkmdaeSqqxsblpLFZD\nqapq3qqrT34ef9zx482jwb7+dbjqqkz/NBJSSIjEcXf2H9vPun3rWF+xnvX71wePFeuprqlmUuEk\npgyawuTCyUweGGzjC8anZ35Hd1JbG4TFqlVw660wZw7ce2/QpCUZpZAQSdGh2kNsqNjA+v3r2VCx\ngQ0Hgufbq7dT1K+IiYUTmVgwsan2MXngZIr7F3fvpqv2OH4c7rgDfvELuOQS6NUr2LKzgz6R+C0n\n563Pc3KaP9OzZ/Pz2DliW/xne/TI9E/daSkkRE7TicYT7KjewebKzWys2MjGAxuDMKlYz5G6I001\njkmFk5hUOImJhRMZXzCes7LPynTRO7e1a4ObYNXXB1ttbbDV1ARBEv869hh7Xl8fjO6Kfba+PuiQ\njz3W1TV//vjxICRaBkiso75Pn5ODJifn5ECK/0z8Y3b2yZ9LFFax88U+Fwu42HuxkOvZM3gvA0vt\nKyRE0qi6prqp9rHxwEY2HdjExgMbKa0spbBvIRMKJjChYEJQCymcyKSBkxibP5bsHholFBn3k4Ok\nrq45cGKBFP9+y3CKD52Wz+NDqmVYxYIv/vhYwMWOO3GiOezq6oLAiNV+YuHRs2dzqLQMpvgaUyyE\n4sMoKysIyNg5Yu998IPBIAMUEiIZ0dDYwK5Du9hSuYXNlZvZdGBTU4DsPLiTYf2HMbFwIhMKJjC+\nYDwTCoM424YAAAAKLElEQVTHMXlj6NWjV6aLL5ng3lzzqa09OUDiA65lIMUHWvx24kQwwbOhIXge\nf+y//mtTf5BCQqSTqW+oZ1v1NjYf2Mzmys1sqdzSFCa7D+1mVN6opgAZlz+OcQXjGF8wnlG5oxQg\n0uEUEiJdSO2JWkqrStlQsYEtlVsorSxla/VWtlRuYe/hvYzIHdHUhDWhcEJTTWRk7kgFiLSLQkLk\nDFF7opatVVvZdGDTSbWP0qpS9hzeQ3H/Ysbmj22qhUwsnMiEwglqwpJWKSREuoG6hjp2VO+gtKqU\nzQfCPpDKTWw+sJndh3czfMBwxheMZ2zeWMYVjGNs/timbUDOgEwXXzJIISHSzdU11LGtahtbKrew\nrXobW6u2UlpVyraq4HmfXn0Ymz826P8I+0DG5I1hTP4YivsX0yNLcwzOZAoJEUnK3dl3dB+lVaWU\nVpYGj2GAbKvexoFjBxiZOzKofYS1kFiQjM0fm/l7fshpU0iISLsdrz/O9urtTbWPrVVBJ3osSAr7\nFjK+YDzj8scxOm80o3JHMSpvFGPzxzJ8wHCthdUFKCREJC1ic0FitZAdB3cEW/UOtlZt5cDxA4zJ\nG9PcfJU3hkkDJ7Fo3CI1YXUiCgkRyYijdUebah7bq7ezrXobS3cupV92P35x9S8Ykz8m00UUFBIi\n0ok0NDZw90t3c9eLd3HXO+7i5tk3a4HEDFNIiEins3bfWm569CY2H9hM8YBiivsXM7T/UAr7FFLY\np5CCPgXk98mnoE9B8Lx3Pvl98snNydWcjw6mkBCRTsndOVh7kN2HdrP78G72Ht5L5fFKKo9XcuD4\nAapqqppeVx2voqqmioM1B+nTq89bwiMvJ4+83nkJgyWvdx75vYNHBcxbKSRE5IzR6I0crj3cFCBV\nx6uorqmmqqaq6Xnl8cqm9+PfO1h7kJweOeT1bg6U+ACJhUrsdfxx+b3z6Zfd74xsGlNIiIgQ1FyO\n1h8NgqNFuMQeK49XcrD2INU11U3vx46vbahtCpNYc1he7zzycvJOCpeW4RPbOuuILoWEiEgHqGuo\na6qpxGopsQCJD5PY8/iQOVx7mH7Z/ZqDJVZziau9tKzFxO9P5/1HFBIiIhnW0NjAodpDJwdIGCjx\nzWbVtYlDJ6dHzlvC5KTaS4L9sUDq3bN3q2VTSIiIdGHuzpG6Iyf3s8Q1kTU1m7VoOovtN+ykZq+8\n3nn87N0/Y0TuCOD0Q6Jnh/2kIiJyysyM/jn96Z/Tn5G5I0/58zUnapo67mMBU9CnoOPK11X+OldN\nQkTk1J1uTUKrc4mISFIKCRERSUohISIiSaU1JMxsuJk9Z2brzGyNmd2S5Lh7zWyzma0ys1npLJOI\niKQu3TWJE8Dn3X0qcD7wGTObHH+AmV0OjHP3CcAngP9Mc5m6vJKSkkwXodPQ76KZfhfN9LvoOGkN\nCXcvc/dV4fMjwHqguMVhVwMPhMcsB3LNrCid5erq9A+gmX4XzfS7aKbfRceJrE/CzEYDs4DlLd4q\nBnbGvd7NW4NEREQyIJKQMLN+wO+AW8MahYiIdAFpn0xnZj2BPwFPufs9Cd7/T+B5d384fL0BuMjd\ny1scp5l0IiLt0NmX5fhv4I1EARF6HPgM8LCZnQdUtwwIOL0fUkRE2ietNQkzWwD8DVgDeLh9BRgF\nuLv/NDzuh8BlwFHgo+6+Im2FEhGRlHWZtZtERCR6XWLGtZldZmYbzGyTmX050+WJUrIJiWaWb2Z/\nMbONZva0meVmuqxRMLMsM1thZo+Hr0eb2Uvhd+M3YR9Yt2BmuWb2iJmtD78f87vj98LMPmdma81s\ntZn92syyu9P3wszuM7NyM1sdty/p9+BUJy93+pAwsyzgh8AiYCrwwZYT8s5wySYk3g781d0nAc8B\n/5zBMkbpVuCNuNffAr7r7hOBauDmjJQqM+4BnnT3KcBMYAPd7HthZsOAzwJz3H0GQT/rB+le34sl\nBP8/xkv4PWjP5OVOHxLAPGCzu+9w93rgIYIJeN1CkgmJwwl+B/eHh90PvCczJYyOmQ0HrgB+Hrf7\nH4Dfh8/vB94bdbkywcwGABe6+xIAdz/h7gfpht8LoAdwVlhb6APsAS6mm3wv3P1FoKrF7pbfg6vj\n9p/S5OWuEBItJ9vtoptOtoubkPgSUBQbBebuZcDgzJUsMncDXyIYAIGZFQJV7t4Yvr8LGJahskVt\nDFBhZkvC5refmllfutn3wt33AN8F3iSYiHsQWEEwSrI7fi9iBrf4HsSC4JQnL3eFkBASTkhsOeLg\njB6BYGbvAsrDWlX8cOjuOjS6JzAH+JG7zyEYGXg73e97kUfw1/EogiA4i2CkpJys3d+DrhASu4H4\ne/oND/d1G2E1+nfAL939sXB3eayaaGZDgH2ZKl9EFgBXmdlW4DcEzUz3EFSXY9/j7vTd2AXsdPdX\nw9e/JwiN7va9eAew1d0r3b0B+CPBdyWvm34vYpJ9D3YDI+KOa/N30xVC4hVgvJmNMrNs4HqCCXjd\nSaIJiY8DHwmf3wQ81vJDZxJ3/4q7j3T3sQTfgefc/UbgeeDa8LAz/vcQEzYl7DSzieGuS4B1dLPv\nBUEz03lm1tvMjObfQ3f7Xhgn16rjvwcfofnnfxz4MEBrk5dPOnFXmCdhZpcR/NWYBdzn7ndluEiR\naWVC4svAbwn+KtgBfMDdqzNVziiZ2UXAF9z9KjMbQzCYIR9YCdwYDnA445nZTIJO/F7AVuCjBJ24\n3ep7YWaLCf5wqCf4DvwjwV/I3eJ7YWYPAguBQqAcWAw8CjxCgu/BqU5e7hIhISIimdEVmptERCRD\nFBIiIpKUQkJERJJSSIiISFIKCRERSUohISIiSSkkpNszs4Zw/aOV4eNtHXjuUWa2pqPOJxK1M3aN\ndZFTcDRc/yhdNBlJuizVJESSLBJoZtvM7FvhzWxeMrOx4f5RZvZseNOWZ8IlzDGzwWb2h3D/ynDZ\nA4Ce4Sqta83sz2aWEx5/S3izoFXhrFmRTkchIQJ9WjQ3XRv3XlV4M5sfESwNA/ADYIm7zwIeDF8D\n3AuUhPvnEKwhBDAB+IG7TyNYyvp94f4vA7PC4z+Zrh9O5HRoWQ7p9szskLsPSLB/G3Cxu28PV+Ld\n6+6DzGw/MMTdG8L9e9x9sJntA4rj1wgys1HAX8I7hBH2d/R09383sycJ1s95FHjU3Y+m/6cVOTWq\nSYi0zpM8PxW1cc8baO4LfBfBrXnnAK/ELW0t0mnoSynS+o2LrgsfrweWhc+XEtxHGeBG4O/h878C\nn4bg3uzhLUZbO/9Id3+B4GZBA4B+p150kfTS6CYR6G1mKwj+M3fgz+7+lfC9fDN7HaihORhuAZaY\n2ReB/QRLdAP8E/BTM7sZOAF8CigjQQ0kbKb6VRgkBtzj7ofS8tOJnAb1SYgkEfZJzHX3ykyXRSRT\n1Nwkkpz+gpJuTzUJERFJSjUJERFJSiEhIiJJKSRERCQphYSIiCSlkBARkaQUEiIiktT/B9Kc0VvE\n/WBfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4154392dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test Set\n",
    "scores_valid, layers_valid = FwdPass(minimum_w,minimum_b,layers,0,xtest,valid_examples)\n",
    "predicted_class_v = np.argmax(scores_valid, axis=1)\n",
    "print (\"Test accuracy: \" , (np.mean(predicted_class_v == ytest)))\n",
    "\n",
    "counter = 0\n",
    "CountPerClass = np.zeros(20)\n",
    "for i in predicted_class_v:\n",
    "    if(predicted_class_v[counter] == ytest[counter]):\n",
    "        CountPerClass[i] += 1\n",
    "    counter += 1\n",
    "for j in range(20):\n",
    "    print (\"Class \", j+1, \"Accuracy is\", CountPerClass[j], \"/500\" , \", Accuracy = \", float(CountPerClass[j])/500)\n",
    "\n",
    "plotter.plot(range(Epochs),Total_Training_Losses, 'g')\n",
    "plotter.plot(range(Epochs),Total_Validation_Losses, 'r')\n",
    "plotter.xlabel('Epochs')\n",
    "plotter.ylabel('Training/Validation Loss')\n",
    "plotter.title('Graph First Run')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy: ', 0.3423)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERGJ6f8Dw5TEMQi/PeIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe682b45e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test Set\n",
    "#One of the old runs/ missing architecture and Hyper Parameters\n",
    "scores_valid, layers_valid = FwdPass(minimum_w2,minimum_b2,layers,0,xtest,valid_examples)\n",
    "predicted_class_v = np.argmax(scores_valid, axis=1)\n",
    "print (\"Test accuracy: \" , (np.mean(predicted_class_v == ytest)))\n",
    "\n",
    "plotter.plot(range(Epochs),Total_Training_Losses2, 'g')\n",
    "plotter.plot(range(Epochs),Total_Validation_Losses2, 'r')\n",
    "plotter.xlabel('Epochs')\n",
    "plotter.ylabel('Training/Validation Loss')\n",
    "plotter.title('Graph First Run')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
